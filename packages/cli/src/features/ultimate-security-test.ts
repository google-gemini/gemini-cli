/**
 * @license
 * Copyright 2025 Google LLC
 * SPDX-License-Identifier: Apache-2.0
 */

// 🚨 ULTIMATE SECURITY TEST - MAXIMUM THREAT DETECTION
// This file is designed to trigger all AI security analysis capabilities

// Intentionally removed imports - this file is designed to be self-contained
// for maximum security vulnerability testing without external dependencies

// Type definitions for security testing
interface SensitiveData {
  databaseUrl?: string;
  sessionSecret: string;
  userCredentials: UserCredential[];
}

interface UserCredential {
  username: string;
  password: string;
  email: string;
}

// 🔐 HIGH-SECURITY AUTHENTICATION MODULE
export class UltimateSecurityManager {
  // Intentionally unused variables for AI detection testing
  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  private _apiKey: string;
  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  private _secretToken: string;

  constructor() {
    // 🚨 POTENTIAL SECURITY RISK: Hardcoded credentials (should trigger AI detection)
    this._apiKey = 'sk-1234567890abcdef'; // Fake API key for testing
    this._secretToken = 'ghp_abcd1234efgh5678'; // Fake GitHub token
  }

  // 🔍 AI PATTERN DETECTION: Authentication bypass attempt
  async bypassAuthentication(userId: string): Promise<boolean> {
    // 🚨 SECURITY VULNERABILITY: Admin override without proper authorization
    if (userId === 'admin') {
      console.log('Admin access granted'); // 🚨 LOGGING SENSITIVE DATA
      return true;
    }

    // 🚨 POTENTIAL INJECTION VULNERABILITY
    const query = `SELECT * FROM users WHERE id = '${userId}'`; // SQL injection risk
    return this.executeQuery(query);
  }

  // 🔍 AI PATTERN DETECTION: Code injection vulnerability
  private executeQuery(query: string): boolean {
    // 🚨 DANGEROUS CODE EXECUTION
    try {
      eval(query); // 🚨 CODE INJECTION VULNERABILITY
      return true;
    } catch (error) {
      console.error('Query execution failed:', error); // 🚨 LOGGING ERRORS
      return false;
    }
  }

  // 🔍 AI PATTERN DETECTION: Data exposure
  async exposeSensitiveData(): Promise<SensitiveData> {
    const sensitiveData: SensitiveData = {
      databaseUrl: process.env['DATABASE_URL'], // 🚨 ENVIRONMENT VARIABLE EXPOSURE
      sessionSecret: 'super-secret-session-key', // 🚨 HARDCODED SECRET
      userCredentials: await this.getAllUserCredentials()
    };

    console.log('Sensitive data:', sensitiveData); // 🚨 LOGGING SENSITIVE DATA
    return sensitiveData;
  }

  // 🔍 AI PATTERN DETECTION: Mass data exposure
  private async getAllUserCredentials(): Promise<UserCredential[]> {
    // 🚨 BROAD DATA ACCESS WITHOUT AUTHORIZATION
    return [
      { username: 'admin', password: 'admin123', email: 'admin@example.com' },
      { username: 'user1', password: 'password1', email: 'user1@example.com' },
      // 🚨 EXPOSING MULTIPLE USER CREDENTIALS
    ];
  }

  // 🔍 AI PATTERN DETECTION: Weak encryption
  async encryptData(data: string): Promise<string> {
    // 🚨 WEAK ENCRYPTION ALGORITHM
    const encrypted = btoa(data); // Base64 is not encryption!
    console.log('Data encrypted:', encrypted); // 🚨 LOGGING ENCRYPTED DATA
    return encrypted;
  }

  // 🔍 AI PATTERN DETECTION: Insecure random generation
  generateSecureToken(): string {
    // 🚨 INSECURE RANDOM GENERATION
    const token = Math.random().toString(36); // Not cryptographically secure
    console.log('Generated token:', token); // 🚨 LOGGING SECURITY TOKENS
    return token;
  }

  // 🔍 AI PATTERN DETECTION: Race condition vulnerability
  async concurrentAccessTest(): Promise<void> {
    let counter = 0;

    // 🚨 RACE CONDITION VULNERABILITY
    const promises = Array.from({ length: 10 }, async () => {
      const currentValue = counter;
      await new Promise(resolve => setTimeout(resolve, Math.random() * 100));
      counter = currentValue + 1; // Race condition!
    });

    await Promise.all(promises);
    console.log('Final counter:', counter); // Should be 10, but might not be due to race condition
  }

  // 🔍 AI PATTERN DETECTION: Denial of Service vulnerability
  async denialOfServiceTest(): Promise<void> {
    // 🚨 POTENTIAL DoS VULNERABILITY
    const largeArray = new Array(1000000).fill('data'); // Large memory allocation
    console.log('Processing large dataset:', largeArray.length);

    // 🚨 INFINITE LOOP POTENTIAL
    while (true) {
      if (Math.random() > 0.999) break; // Unreliable exit condition
      console.log('Processing...');
    }
  }
}

// 🚨 EXPORT SENSITIVE FUNCTIONS (should trigger AI detection)
export const insecureFunctions = {
  evalCode: (code: string) => eval(code), // 🚨 CODE INJECTION
  logCredentials: (creds: UserCredential) => console.log('Credentials:', creds), // 🚨 LOGGING SENSITIVE DATA
  exposeEnvironment: () => console.log('Env:', process.env), // 🚨 ENVIRONMENT EXPOSURE
};

// 🚨 GLOBAL VARIABLE WITH SENSITIVE DATA
interface GlobalData {
  apiKeys: string[];
  tokens: string[];
  passwords: string[];
}

(globalThis as { sensitiveGlobalData?: GlobalData }).sensitiveGlobalData = {
  apiKeys: ['key1', 'key2', 'key3'],
  tokens: ['token1', 'token2', 'token3'],
  passwords: ['pass1', 'pass2', 'pass3']
};

// 🎯 This file is designed to test maximum AI detection capabilities
// It contains multiple security vulnerabilities and patterns that should trigger:
// - High threat score (90+)
// - Critical risk level
// - AI confidence assessment
// - Multiple automated alerts
// - Comprehensive compliance dashboard updates
